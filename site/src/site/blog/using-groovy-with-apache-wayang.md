---
layout: post
title: Using Groovy with Apache Wayang and Apache Spark
date: '2022-06-19T13:01:07+00:00'
permalink: using-groovy-with-apache-wayang
---
<p><img src="https://blogs.apache.org/groovy/mediaresource/870eadc0-670a-4b58-86d0-0007c3f2f4b1" align="right" style="width: 10%;" alt="wayang.png"><a href="https://wayang.apache.org/" target="_blank">Apache Wayang</a>&nbsp;(incubating) is an API for big data cross-platform processing. It provides an abstraction over other platforms like <a href="https://spark.apache.org/" target="_blank">Apache Spark</a>&nbsp;and <a href="https://flink.apache.org/" target="_blank">Apache Flink</a> as well as a default built-in stream-based "platform". The goal is to provide a consistent developer experience when writing code regardless of whether a light-weight or highly-scalable platform may eventually be required. Execution of the application is specified in a logical plan which is again platform agnostic. Wayang will transform the logical plan into a set of physical operators to be executed by specific underlying processing platforms.</p>
<h3>Whiskey Clustering</h3>
<p><img src="https://blogs.apache.org/groovy/mediaresource/c5ba5e59-737e-4ebf-91c9-08fa67dc8f70" align="right" alt="groovy.png" style="width: 15%;">We'll take a look at using Apache Wayang with Groovy to help us in the quest to find the perfect&nbsp;single-malt Scotch whiskey. The whiskies produced from&nbsp;<a href="https://www.niss.org/sites/default/files/ScotchWhisky01.txt" rel="nofollow" style="transition: color 80ms cubic-bezier(0.33, 1, 0.68, 1) 0s, background-color 0s ease 0s, box-shadow 0s ease 0s, border-color 0s ease 0s;">86 distilleries</a>&nbsp;have been ranked by expert tasters according to 12 criteria (Body, Sweetness, Malty, Smoky, Fruity, etc.). We'll use a KMeans algorithm to calculate the centroids. This is similar to the <a href="https://github.com/apache/incubator-wayang/blob/main/README.md#k-means" target="_blank">KMeans example in the Wayang documentation</a> but instead of 2 dimensions (x and y coordinates), we have 12 dimensions corresponding to our criteria. The main point is that it is illustrative of typical data science and machine learning algorithms involving iteration (the typical map, filter, reduce style of processing).</p><p><img src="https://blogs.apache.org/groovy/mediaresource/8d458e7c-8993-470a-8afd-44a46cd2b500" alt="whiskey_bottles.jpg"></p><p>KMeans is a standard data-science clustering technique. In our case, it groups whiskies with similar characteristics (according to the 12 criteria) into clusters. If we have a favourite whiskey, chances are we can find something similar by looking at other instances in the same cluster. If we are feeling like a change, we can look for a whiskey in some other cluster. The centroid is the notional "point" in the middle of the cluster. For us it reflects the typical measure of each criteria for a whiskey in that cluster.</p>
<h3>Implementation Details</h3>
<p>We'll start with defining a Point record:</p><pre style="background-color:#ffffff;color:#080808;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#0033b3;">record </span><span style="color:#000000;">Point</span>(<span style="color:#0033b3;">double</span>[] pts) <span style="color:#0033b3;">implements </span><span style="color:#000000;">Serializable </span>{<br>    <span style="color:#0033b3;">static </span><span style="color:#000000;">Point </span><span style="color:#00627a;">fromLine</span>(<span style="color:#000000;">String </span>line) { <span style="color:#0033b3;">new </span><span style="color:#000000;">Point</span>(line.split(<span style="color:#067d17;">'</span><span style="color:#067d17;background-color:#edfced;">,</span><span style="color:#067d17;">'</span>)[<span style="color:#1750eb;">2</span>..-<span style="color:#1750eb;">1</span>]*.toDouble() <span style="color:#0033b3;">as double</span>[]) }<br>}<br></pre><p>We've made it&nbsp;<span style="font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">Serializable</span>&nbsp;(more on that later) and included a&nbsp;<span style="color: rgb(0, 98, 122); font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">fromLine</span>&nbsp;factory method to help us make points from a CSV file. We'll do that ourselves rather than rely on other libraries which could assist. It's not a 2D or 3D point for us but 12D corresponding to the 12 criteria. We just use a&nbsp;<span style="color: rgb(0, 51, 179); font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">double</span>&nbsp;array, so any dimension would be supported but the 12 comes from the number of columns in our data file.</p><p>We'll define a related&nbsp;<span style="font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">TaggedPointCounter</span>&nbsp;record. It's like a&nbsp;<span style="font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">Point</span>&nbsp;but tracks a cluster Id and count used when clustering the "points":</p><pre style="background-color:#ffffff;color:#080808;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#0033b3;">record </span><span style="color:#000000;">TaggedPointCounter</span>(<span style="color:#0033b3;">double</span>[] pts, <span style="color:#0033b3;">int </span>cluster, <span style="color:#0033b3;">long </span>count) <span style="color:#0033b3;">implements </span><span style="color:#000000;">Serializable </span>{<br>    <span style="color:#000000;">TaggedPointCounter </span><span style="color:#00627a;">plus</span>(<span style="color:#000000;">TaggedPointCounter </span>that) {<br>        <span style="color:#0033b3;">new </span><span style="color:#000000;">TaggedPointCounter</span>((<span style="color:#1750eb;">0</span>..&lt;<span style="color:#871094;">pts</span>.size()).collect<span style="font-weight:bold;">{ </span><span style="color:#871094;">pts</span>[it] + that.<span style="color:#871094;">pts</span>[it] <span style="font-weight:bold;">} </span><span style="color:#0033b3;">as double</span>[], <span style="color:#871094;">cluster</span>, <span style="color:#871094;">count </span>+ that.<span style="color:#871094;">count</span>)<br>    }<br><br>    <span style="color:#000000;">TaggedPointCounter </span><span style="color:#00627a;">average</span>() {<br>        <span style="color:#0033b3;">new </span><span style="color:#000000;">TaggedPointCounter</span>(<span style="color:#871094;">pts</span>.collect<span style="font-weight:bold;">{ </span><span style="color:#0033b3;">double </span>d <span style="font-weight:bold;">-&gt; </span>d/<span style="color:#871094;">count </span><span style="font-weight:bold;">} </span><span style="color:#0033b3;">as double</span>[], <span style="color:#871094;">cluster</span>, <span style="color:#1750eb;">0</span>)<br>    }<br>}<br></pre><p>We have&nbsp;<span style="color: rgb(0, 98, 122); font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">plus</span>&nbsp;and&nbsp;<span style="color: rgb(0, 98, 122); font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">average</span>&nbsp;methods which will be helpful in the map/reduce parts of the algorithm.</p><p>Another aspect of the KMeans algorithm is assigning points to the cluster associated with their nearest centroid. For 2 dimensions, recalling pythagoras' theorem, this would be the square root of x squared plus y squared, where x and y are the distance of a point from the centroid in the x and y dimensions respectively. We'll do the same across all dimensions and define the following helper class to capture this part of the algorithm:</p><pre style="background-color:#ffffff;color:#080808;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#0033b3;">class </span><span style="color:#000000;">SelectNearestCentroid </span><span style="color:#0033b3;">implements </span><span style="color:#000000;">ExtendedSerializableFunction</span>&lt;<span style="color:#000000;">Point</span>, <span style="color:#000000;">TaggedPointCounter</span>&gt; {<br>    <span style="color:#000000;">Iterable</span>&lt;<span style="color:#000000;">TaggedPointCounter</span>&gt; <span style="color:#871094;">centroids<br></span><span style="color:#871094;"><br></span><span style="color:#871094;">    </span><span style="color:#0033b3;">void </span><span style="color:#00627a;">open</span>(<span style="color:#000000;">ExecutionContext </span>context) {<br>        <span style="color:#871094;">centroids </span>= context.getBroadcast(<span style="color:#067d17;">"centroids"</span>)<br>    }<br><br>    <span style="color:#000000;">TaggedPointCounter </span><span style="color:#00627a;">apply</span>(<span style="color:#000000;">Point </span>p) {<br>        <span style="color:#0033b3;">def </span>minDistance = <span style="color:#000000;">Double</span>.<span style="color:#871094;font-style:italic;">POSITIVE_INFINITY<br></span><span style="color:#871094;font-style:italic;">        </span><span style="color:#0033b3;">def </span>nearestCentroidId = -<span style="color:#1750eb;">1<br></span><span style="color:#1750eb;">        </span><span style="color:#0033b3;">for </span>(c <span style="color:#0033b3;">in </span><span style="color:#871094;">centroids</span>) {<br>            <span style="color:#0033b3;">def </span><span style="color:#000000;">distance </span>= <span style="font-style:italic;">sqrt</span>((<span style="color:#1750eb;">0</span>..&lt;p.<span style="color:#871094;">pts</span>.size()).collect<span style="font-weight:bold;">{ </span>p.<span style="color:#871094;">pts</span>[it] - c.<span style="color:#871094;">pts</span>[it] <span style="font-weight:bold;">}</span>.sum<span style="font-weight:bold;">{ </span>it ** <span style="color:#1750eb;">2 </span><span style="font-weight:bold;">} </span><span style="color:#0033b3;">as double</span>)<br>            <span style="color:#0033b3;">if </span>(<span style="color:#000000;">distance </span>&lt; minDistance) {<br>                minDistance = <span style="color:#000000;">distance<br></span><span style="color:#000000;">                </span>nearestCentroidId = c.<span style="color:#871094;">cluster<br></span><span style="color:#871094;">            </span>}<br>        }<br>        <span style="color:#0033b3;">new </span><span style="color:#000000;">TaggedPointCounter</span>(p.<span style="color:#871094;">pts</span>, nearestCentroidId, <span style="color:#1750eb;">1</span>)<br>    }<br>}</pre><p style="">In Wayang parlance, the&nbsp;<span style="font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">SelectNearestCentroid</span>&nbsp;class is a <i>UDF</i>, a User-Defined Function. It represents some chunk of functionality where an optimization decision can be made about where to run the operation.</p><p></p><p></p><p style="">Once we get to using Spark, the classes in the map/reduce part of our algorithm will need to be serializable. Method closures in dynamic Groovy aren't serializable. We have a few options to avoid using them. I'll show one approach here which is to use some helper classes in places where we might typically use method references. Here are the helper classes:</p><pre style="background-color:#ffffff;color:#080808;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#0033b3;">class </span><span style="color:#000000;">Cluster </span><span style="color:#0033b3;">implements </span><span style="color:#000000;">SerializableFunction</span>&lt;<span style="color:#000000;">TaggedPointCounter</span>, <span style="color:#000000;">Integer</span>&gt; {<br>    <span style="color:#000000;">Integer </span><span style="color:#00627a;">apply</span>(<span style="color:#000000;">TaggedPointCounter </span>tpc) { tpc.cluster() }<br>}<br><br><span style="color:#0033b3;">class </span><span style="color:#000000;">Average </span><span style="color:#0033b3;">implements </span><span style="color:#000000;">SerializableFunction</span>&lt;<span style="color:#000000;">TaggedPointCounter</span>, <span style="color:#000000;">TaggedPointCounter</span>&gt; {<br>    <span style="color:#000000;">TaggedPointCounter </span><span style="color:#00627a;">apply</span>(<span style="color:#000000;">TaggedPointCounter </span>tpc) { tpc.average() }<br>}<br><br><span style="color:#0033b3;">class </span><span style="color:#000000;">Plus </span><span style="color:#0033b3;">implements </span><span style="color:#000000;">SerializableBinaryOperator</span>&lt;<span style="color:#000000;">TaggedPointCounter</span>&gt; {<br>    <span style="color:#000000;">TaggedPointCounter </span><span style="color:#00627a;">apply</span>(<span style="color:#000000;">TaggedPointCounter </span>tpc1, <span style="color:#000000;">TaggedPointCounter </span>tpc2) { tpc1.plus(tpc2) }<br>}<br></pre><p style="">Now we are ready for our KMeans script:<br></p><pre style="background-color:#ffffff;color:#080808;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#0033b3;">int </span><span style="color:#000000;">k </span>= <span style="color:#1750eb;">5<br></span><span style="color:#0033b3;">int </span><span style="color:#000000;">iterations </span>= <span style="color:#1750eb;">20<br></span><span style="color:#1750eb;"><br></span><span style="color:#8c8c8c;font-style:italic;">// read in data from our file<br></span><span style="color:#0033b3;">def </span><span style="color:#000000;">url </span>= <span style="color:#000000;">WhiskeyWayang</span>.classLoader.getResource(<span style="color:#067d17;">'whiskey.csv'</span>).file<br><span style="color:#0033b3;">def </span><span style="color:#000000;">pointsData </span>= <span style="color:#0033b3;">new </span><span style="color:#000000;">File</span>(<span style="color:#000000;">url</span>).readLines()[<span style="color:#1750eb;">1</span>..-<span style="color:#1750eb;">1</span>].collect<span style="font-weight:bold;">{ </span><span style="color:#000000;">Point</span>.<span style="font-style:italic;">fromLine</span>(it) <span style="font-weight:bold;">}<br></span><span style="color:#0033b3;">def </span><span style="color:#000000;">dims </span>= <span style="color:#000000;">pointsData</span>[<span style="color:#1750eb;">0</span>].pts().size()<br><br><span style="color:#8c8c8c;font-style:italic;">// create some random points as initial centroids<br></span><span style="color:#0033b3;">def </span><span style="color:#000000;">r </span>= <span style="color:#0033b3;">new </span><span style="color:#000000;">Random</span>()<br><span style="color:#0033b3;">def </span><span style="color:#000000;">initPts </span>= (<span style="color:#1750eb;">1</span>..<span style="color:#000000;">k</span>).collect <span style="font-weight:bold;">{ </span>(<span style="color:#1750eb;">0</span>..&lt;<span style="color:#000000;">dims</span>).collect <span style="font-weight:bold;">{ </span><span style="color:#000000;">r</span>.nextGaussian() + <span style="color:#1750eb;">2 </span><span style="font-weight:bold;">} </span><span style="color:#0033b3;">as double</span>[] <span style="font-weight:bold;">}<br></span><span style="font-weight:bold;"><br></span><span style="color:#8c8c8c;font-style:italic;">// create planbuilder with Java and Spark enabled<br></span><span style="color:#0033b3;">def </span><span style="color:#000000;">configuration </span>= <span style="color:#0033b3;">new </span><span style="color:#000000;">Configuration</span>()<br><span style="color:#0033b3;">def </span><span style="color:#000000;">context </span>= <span style="color:#0033b3;">new </span><span style="color:#000000;">WayangContext</span>(<span style="color:#000000;">configuration</span>)<br>    .withPlugin(<span style="color:#000000;">Java</span>.<span style="font-style:italic;">basicPlugin</span>())<br>    .withPlugin(<span style="color:#000000;">Spark</span>.<span style="font-style:italic;">basicPlugin</span>())<br><span style="color:#0033b3;">def </span><span style="color:#000000;">planBuilder </span>= <span style="color:#0033b3;">new </span><span style="color:#000000;">JavaPlanBuilder</span>(<span style="color:#000000;">context</span>, <span style="color:#067d17;">"KMeans (</span>$<span style="color:#000000;">url</span><span style="color:#067d17;">, k=</span>$<span style="color:#000000;">k</span><span style="color:#067d17;">, iterations=</span>$<span style="color:#000000;">iterations</span><span style="color:#067d17;">)"</span>)<br><br><span style="color:#0033b3;">def </span><span style="color:#000000;">points </span>= <span style="color:#000000;">planBuilder<br></span><span style="color:#000000;">    </span>.loadCollection(<span style="color:#000000;">pointsData</span>).withName(<span style="color:#067d17;">'Load points'</span>)<br><br><span style="color:#0033b3;">def </span><span style="color:#000000;">initialCentroids </span>= <span style="color:#000000;">planBuilder<br></span><span style="color:#000000;">    </span>.loadCollection((<span style="color:#1750eb;">0</span>..&lt;<span style="color:#000000;">k</span>).collect<span style="font-weight:bold;">{ </span>idx <span style="font-weight:bold;">-&gt; </span><span style="color:#0033b3;">new </span><span style="color:#000000;">TaggedPointCounter</span>(<span style="color:#000000;">initPts</span>[idx], idx, <span style="color:#1750eb;">0</span>) <span style="font-weight:bold;">}</span>)<br>    .withName(<span style="color:#067d17;">"Load random centroids"</span>)<br><br><span style="color:#0033b3;">def </span><span style="color:#000000;">finalCentroids </span>= <span style="color:#000000;">initialCentroids<br></span><span style="color:#000000;">    </span>.repeat(<span style="color:#000000;">iterations</span>, currentCentroids -&gt;<br>        <span style="color:#000000;">points</span>.map(<span style="color:#0033b3;">new </span><span style="color:#000000;">SelectNearestCentroid</span>())<br>            .withBroadcast(currentCentroids, <span style="color:#067d17;">"centroids"</span>).withName(<span style="color:#067d17;">"Find nearest centroid"</span>)<br>            .reduceByKey(<span style="color:#0033b3;">new </span><span style="color:#000000;">Cluster</span>(), <span style="color:#0033b3;">new </span><span style="color:#000000;">Plus</span>()).withName(<span style="color:#067d17;">"Add up points"</span>)<br>            .map(<span style="color:#0033b3;">new </span><span style="color:#000000;">Average</span>()).withName(<span style="color:#067d17;">"Average points"</span>)<br>            .withOutputClass(<span style="color:#000000;">TaggedPointCounter</span>)).withName(<span style="color:#067d17;">"Loop"</span>).collect()<br><br>println <span style="color:#067d17;">'Centroids:'<br></span><span style="color:#000000;">finalCentroids</span>.each <span style="font-weight:bold;">{ </span>c <span style="font-weight:bold;">-&gt;<br></span><span style="font-weight:bold;">    </span>println <span style="color:#067d17;">"Cluster</span>$c.<span style="color:#871094;">cluster</span><span style="color:#067d17;">: </span>$<span style="font-weight:bold;">{</span>c.<span style="color:#871094;">pts</span>.collect<span style="font-weight:bold;">{ </span>sprintf(<span style="color:#067d17;">'%.3f'</span>, it) <span style="font-weight:bold;">}</span>.join(<span style="color:#067d17;">', '</span>)<span style="font-weight:bold;">}</span><span style="color:#067d17;">"<br></span><span style="font-weight:bold;">}<br></span></pre><p style="">Here,&nbsp;<span style="color: rgb(36, 41, 47); font-family: ui-monospace, SFMono-Regular, &quot;SF Mono&quot;, Menlo, Consolas, &quot;Liberation Mono&quot;, monospace; font-size: 12px; white-space: pre;">k</span>&nbsp;is the desired number of clusters, and&nbsp;<span style="color: rgb(36, 41, 47); font-family: ui-monospace, SFMono-Regular, &quot;SF Mono&quot;, Menlo, Consolas, &quot;Liberation Mono&quot;, monospace; font-size: 12px; white-space: pre;">iterations</span>&nbsp;is the number of times to iterate through the KMeans loop. The&nbsp;<span style="color: rgb(36, 41, 47); font-family: ui-monospace, SFMono-Regular, &quot;SF Mono&quot;, Menlo, Consolas, &quot;Liberation Mono&quot;, monospace; font-size: 12px; white-space: pre;">pointsData</span>&nbsp;variable is a list of&nbsp;<span style="font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">Point</span>&nbsp;instances loaded from our data file. We'd use the&nbsp;<span style="color: rgb(8, 8, 8); font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">readTextFile</span>&nbsp;method instead of&nbsp;<span style="color: rgb(8, 8, 8); font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">loadCollection</span>&nbsp;if our data set was large. The&nbsp;<span style="font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">initPts</span>&nbsp;variable is some random starting positions for our initial centroids. Being random, and given the way the KMeans algorithm works, it is possible that some of our clusters may have no points assigned.</p><p style="">Our algorithm works by assigning, at each iteration, all the points to their closest current centroid and then calculating the new centroids given those assignments. Finally, we output the results.
</p><h3>Running with the Java streams-backed platform</h3>As we mentioned earlier, Wayang selects which platform(s) will run our application. It has numerous capabilities whereby cost functions and load estimators can be used to influence and optimize how the application is run. For our simple example, it is enough to know that even though we specified Java or Spark as options, Wayang knows that for our small data set, the Java streams option is the way to go.<p></p><p>Since we prime the algorithm with random data, we expect the results to be slightly different each time
the script is run, but here is one output:</p><p></p><pre style="background-color:#ffffff;color:#080808;font-family:'JetBrains Mono',monospace;font-size:9.6pt;">&gt; Task :WhiskeyWayang:run<br>Centroids:<br>Cluster0: <span style="color:#1750eb;">2.548</span>, <span style="color:#1750eb;">2.419</span>, <span style="color:#1750eb;">1.613</span>, <span style="color:#1750eb;">0.194</span>, <span style="color:#1750eb;">0.097</span>, <span style="color:#1750eb;">1.871</span>, <span style="color:#1750eb;">1.742</span>, <span style="color:#1750eb;">1.774</span>, <span style="color:#1750eb;">1.677</span>, <span style="color:#1750eb;">1.935</span>, <span style="color:#1750eb;">1.806</span>, <span style="color:#1750eb;">1.613<br></span>Cluster2: <span style="color:#1750eb;">1.464</span>, <span style="color:#1750eb;">2.679</span>, <span style="color:#1750eb;">1.179</span>, <span style="color:#1750eb;">0.321</span>, <span style="color:#1750eb;">0.071</span>, <span style="color:#1750eb;">0.786</span>, <span style="color:#1750eb;">1.429</span>, <span style="color:#1750eb;">0.429</span>, <span style="color:#1750eb;">0.964</span>, <span style="color:#1750eb;">1.643</span>, <span style="color:#1750eb;">1.929</span>, <span style="color:#1750eb;">2.179<br></span>Cluster3: <span style="color:#1750eb;">3.250</span>, <span style="color:#1750eb;">1.500</span>, <span style="color:#1750eb;">3.250</span>, <span style="color:#1750eb;">3.000</span>, <span style="color:#1750eb;">0.500</span>, <span style="color:#1750eb;">0.250</span>, <span style="color:#1750eb;">1.625</span>, <span style="color:#1750eb;">0.375</span>, <span style="color:#1750eb;">1.375</span>, <span style="color:#1750eb;">1.375</span>, <span style="color:#1750eb;">1.250</span>, <span style="color:#1750eb;">0.250<br></span>Cluster4: <span style="color:#1750eb;">1.684</span>, <span style="color:#1750eb;">1.842</span>, <span style="color:#1750eb;">1.211</span>, <span style="color:#1750eb;">0.421</span>, <span style="color:#1750eb;">0.053</span>, <span style="color:#1750eb;">1.316</span>, <span style="color:#1750eb;">0.632</span>, <span style="color:#1750eb;">0.737</span>, <span style="color:#1750eb;">1.895</span>, <span style="color:#1750eb;">2.000</span>, <span style="color:#1750eb;">1.842</span>, <span style="color:#1750eb;">1.737
...</span></pre><p style="">Which if plotted looks like this:</p><p><a href="https://blogs.apache.org/groovy/mediaresource/a74aff16-03f8-4aec-b7a8-e1ce7133efef"><img src="https://blogs.apache.org/groovy/mediaresource/a74aff16-03f8-4aec-b7a8-e1ce7133efef" alt="WhiskeyWayang Centroid Spider Plot" style="width: 50%;"></a><br></p><p>If you are interested, check out the examples in the repo links at the end of this article to see the code for producing this centroid spider plot or the Jupyter/BeakerX notebook in this project's github repo.</p>
<h3>Running with Apache Spark</h3>
<p><img src="https://blogs.apache.org/groovy/mediaresource/ab92d040-080c-414b-b33f-193772a341fc" align="right" style="width: 10%;" alt="spark.png">Given our small dataset size and no other customization, Wayang will choose the Java streams based solution. We could use Wayang optimization features to influence which processing platform it chooses, but to keep things simple, we'll just disable the Java streams platform in our configuration by making the following change in our code:</p><p><img src="https://blogs.apache.org/groovy/mediaresource/c26f8929-215b-423b-9870-7bc8f18ff874" alt="WhiskeyWayang_DisableJava.png"></p>
<p>Now when we run the application, the output will be something like this (a solution similar to before but with 1000+ extra lines of Spark and Wayang log information - truncated for presentation purposes):</p>
<pre style="background-color:#ffffff;color:#080808;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><p><span style="color: rgb(156, 0, 0);">[main] INFO org.apache.spark.SparkContext - Running Spark version 3.3.0<br>[main] INFO org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 62081.<br>...<br></span>Centroids:<br>Cluster4: 1.414, 2.448, 0.966, 0.138, 0.034, 0.862, 1.000, 0.483, 1.345, 1.690, 2.103, 2.138<br>Cluster0: 2.773, 2.455, 1.455, 0.000, 0.000, 1.909, 1.682, 1.955, 2.091, 2.045, 2.136, 1.818<br>Cluster1: 1.762, 2.286, 1.571, 0.619, 0.143, 1.714, 1.333, 0.905, 1.190, 1.952, 1.095, 1.524<br>Cluster2: 3.250, 1.500, 3.250, 3.000, 0.500, 0.250, 1.625, 0.375, 1.375, 1.375, 1.250, 0.250<br>Cluster3: 2.167, 2.000, 2.167, 1.000, 0.333, 0.333, 2.000, 0.833, 0.833, 1.500, 2.333, 1.667<br><span style="color: rgb(156, 0, 0);">...<br>[shutdown-hook-0] INFO org.apache.spark.SparkContext - Successfully stopped SparkContext<br>[shutdown-hook-0] INFO org.apache.spark.util.ShutdownHookManager - Shutdown hook called</span></p></pre>
<h3>Discussion</h3>
<p>A goal of Apache Wayang is to allow developers to write platform-agnostic applications. While this is mostly true, the abstractions aren't perfect. As an example, if I know I am only using the streams-backed platform, I don't need to worry about making any of my classes serializable (which is a Spark requirement). In our example, we could have omitted the "<span style="font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt; color: rgb(0, 51, 179);">implements </span><span style="font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">Serializable</span>" part of the&nbsp;<span style="font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">TaggedPointCounter</span>&nbsp;record, and we could have used a method reference&nbsp;<span style="font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">TaggedPointCounter::average </span>instead of our&nbsp;<span style="font-family: &quot;JetBrains Mono&quot;, monospace; font-size: 9.6pt;">Average</span>&nbsp;helper class. This isn't meant to be a criticism of Wayang, after all if you want to write cross-platform UDFs, you might expect to have to follow some rules. Instead, it is meant to just indicate that abstractions often have leaks around the edges. Sometimes those leaks can be beneficially used, other times they are traps waiting for unknowing developers.</p><p>To summarise, if using the Java streams-backed platform, you can run the application on JDK17 (which uses native records) as well as JDK11 and JDK8 (where Groovy provides emulated records). Also, we could make numerous simplifications if we desired. When using the Spark processing platform, the potential simplifications aren't applicable, and we can run on JDK8 and JDK11 (Spark isn't yet supported on JDK17).</p>
<h3>Conclusion</h3><p>We have looked at using Apache Wayang to implement a KMeans algorithm that runs either backed by the JDK streams capabilities or by Apache Spark. The Wayang API hid from us some of the complexities of writing code that works on a distributed platform and some of the intricacies of dealing with the Spark platform. The abstractions aren't perfect but they certainly aren't hard to use and provide extra protection should we wish to move between platforms. As an added bonus, they open up numerous optimization possibilities.</p><p>Apache Wayang is an incubating project at Apache and still has work to do before it graduates but lots of work has gone on previously (it was previously known as Rheem and was started in 2015). Platform agnostic applications is a holy grail that has been desired for many years but is hard to achieve. It should be exciting to see how far Apache Wayang progresses in achieving this goal.</p>
<p></p>
<h3>More Information</h3>
<p></p><ul>
<li>Repo containing the source code:
<a href="https://github.com/paulk-asert/groovy-data-science/tree/master/subprojects/WhiskeyWayang">WhiskeyWayang</a></li>
<li>Repo containing similar examples using a variety of libraries including Apache Commons CSV,
Weka, Smile, Tribuo and others:
<a href="https://github.com/paulk-asert/groovy-data-science/tree/master/subprojects/Whiskey">Whiskey</a></li>
<li>A similar example using Apache Spark directly but with a built-in parallelized KMeans from the spark-mllib library rather than a hand-crafted algorithm:
<a href="https://github.com/paulk-asert/groovy-data-science/tree/master/subprojects/WhiskeySpark" style="background-color: rgb(255, 255, 255);">WhiskeySpark</a><br></li>
<li>A similar example using Apache Ignite directly but with a built-in clustered KMeans from the ignite-ml library rather than a hand-crafted algorithm:
<a href="https://github.com/paulk-asert/groovy-data-science/tree/master/subprojects/WhiskeyIgnite" style="background-color: rgb(255, 255, 255);">WhiskeyIgnite</a><br></li>
</ul><p></p>
